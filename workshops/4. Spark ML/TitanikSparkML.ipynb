{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit, avg\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkTitanikJob\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.49:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTitanikJob</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae89d8f910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = spark.read.csv('train.csv', header = 'True', inferSchema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_count = titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gropuBy_output = titanic_df.groupBy(\"Survived\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gropuBy_output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_age = round(titanic_df.select(avg(col('Age'))).collect()[0][0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.fillna({'Age': avg_age})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.0|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.0|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.0|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.fillna({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('Alone',lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+--------+-----------+-----+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Embarked|Family_Size|Alone|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+--------+-----------+-----+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25|       S|          1|    0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|       C|          1|    0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+--------+-----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "titanic_df = pipeline.fit(titanic_df).transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|\n",
      "|       0|     3|30.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|\n",
      "|       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|\n",
      "|       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|\n",
      "|       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|\n",
      "|       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|\n",
      "|       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|\n",
      "|       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|\n",
      "|       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|\n",
      "|       1|     2|30.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|\n",
      "|       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|\n",
      "|       1|     3|30.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+--------------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+--------------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|[3.0,22.0,1.0,0.0...|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|[1.0,38.0,1.0,0.0...|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|[3.0,26.0,0.0,0.0...|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|[1.0,35.0,1.0,0.0...|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[3.0...|\n",
      "|       0|     3|30.0|    0|    0| 8.4583|          0|    1|      0.0|           2.0|[3.0,30.0,0.0,0.0...|\n",
      "|       0|     1|54.0|    0|    0|51.8625|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     3| 2.0|    3|    1| 21.075|          4|    0|      0.0|           0.0|[3.0,2.0,3.0,1.0,...|\n",
      "|       1|     3|27.0|    0|    2|11.1333|          2|    0|      1.0|           0.0|[3.0,27.0,0.0,2.0...|\n",
      "|       1|     2|14.0|    1|    0|30.0708|          1|    0|      1.0|           1.0|[2.0,14.0,1.0,0.0...|\n",
      "|       1|     3| 4.0|    1|    1|   16.7|          2|    0|      1.0|           0.0|[3.0,4.0,1.0,1.0,...|\n",
      "|       1|     1|58.0|    0|    0|  26.55|          0|    1|      1.0|           0.0|[1.0,58.0,0.0,0.0...|\n",
      "|       0|     3|20.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[3.0...|\n",
      "|       0|     3|39.0|    1|    5| 31.275|          6|    0|      0.0|           0.0|[3.0,39.0,1.0,5.0...|\n",
      "|       0|     3|14.0|    0|    0| 7.8542|          0|    1|      1.0|           0.0|[3.0,14.0,0.0,0.0...|\n",
      "|       1|     2|55.0|    0|    0|   16.0|          0|    1|      1.0|           0.0|[2.0,55.0,0.0,0.0...|\n",
      "|       0|     3| 2.0|    4|    1| 29.125|          5|    0|      0.0|           2.0|[3.0,2.0,4.0,1.0,...|\n",
      "|       1|     2|30.0|    0|    0|   13.0|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[2.0...|\n",
      "|       0|     3|31.0|    1|    0|   18.0|          1|    0|      1.0|           0.0|[3.0,31.0,1.0,0.0...|\n",
      "|       1|     3|30.0|    0|    0|  7.225|          0|    1|      1.0|           1.0|[3.0,30.0,0.0,0.0...|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = feature_vector.randomSplit([0.8, 0.2],seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+--------+-----------+-----+---------+--------------+--------------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|    Fare|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
      "+--------+------+----+-----+-----+--------+-----------+-----+---------+--------------+--------------------+\n",
      "|       0|     1| 2.0|    1|    2|  151.55|          3|    0|      1.0|           0.0|[1.0,2.0,1.0,2.0,...|\n",
      "|       0|     1|21.0|    0|    1| 77.2875|          1|    0|      0.0|           0.0|[1.0,21.0,0.0,1.0...|\n",
      "|       0|     1|22.0|    0|    0|135.6333|          0|    1|      0.0|           1.0|[1.0,22.0,0.0,0.0...|\n",
      "|       0|     1|24.0|    0|    0|    79.2|          0|    1|      0.0|           1.0|[1.0,24.0,0.0,0.0...|\n",
      "|       0|     1|24.0|    0|    1|247.5208|          1|    0|      0.0|           1.0|[1.0,24.0,0.0,1.0...|\n",
      "|       0|     1|25.0|    1|    2|  151.55|          3|    0|      1.0|           0.0|[1.0,25.0,1.0,2.0...|\n",
      "|       0|     1|27.0|    0|    2|   211.5|          2|    0|      0.0|           1.0|[1.0,27.0,0.0,2.0...|\n",
      "|       0|     1|28.0|    0|    0|    47.1|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     1|28.0|    1|    0| 82.1708|          1|    0|      0.0|           1.0|[1.0,28.0,1.0,0.0...|\n",
      "|       0|     1|29.0|    0|    0|    30.0|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     1|30.0|    0|    0|     0.0|          0|    1|      0.0|           0.0|(9,[0,1,6],[1.0,3...|\n",
      "|       0|     1|30.0|    0|    0|     0.0|          0|    1|      0.0|           0.0|(9,[0,1,6],[1.0,3...|\n",
      "|       0|     1|30.0|    0|    0|    26.0|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     1|30.0|    0|    0|   26.55|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     1|30.0|    0|    0| 27.7208|          0|    1|      0.0|           1.0|[1.0,30.0,0.0,0.0...|\n",
      "|       0|     1|30.0|    0|    0| 27.7208|          0|    1|      0.0|           1.0|[1.0,30.0,0.0,0.0...|\n",
      "|       0|     1|30.0|    0|    0|   27.75|          0|    1|      0.0|           1.0|[1.0,30.0,0.0,0.0...|\n",
      "|       0|     1|30.0|    0|    0| 30.6958|          0|    1|      0.0|           1.0|[1.0,30.0,0.0,0.0...|\n",
      "|       0|     1|30.0|    0|    0|    31.0|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "|       0|     1|30.0|    0|    0|    35.0|          0|    1|      0.0|           0.0|(9,[0,1,4,6],[1.0...|\n",
      "+--------+------+----+-----+-----+--------+-----------+-----+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|[1.0,18.0,1.0,0.0...|\n",
      "|       1.0|       0|[1.0,19.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|(9,[0,1,4,6],[1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(training_data)\n",
    "lr_prediction = lrModel.transform(test_data)\n",
    "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression [Accuracy] = 0.793103\n",
      "LogisticRegression [Error] = 0.206897 \n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"LogisticRegression [Accuracy] = %g\"% (lr_accuracy))\n",
    "print(\"LogisticRegression [Error] = %g \" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,18.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|(9,[0,1,4,6],[1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(training_data)\n",
    "dt_prediction = dt_model.transform(test_data)\n",
    "\n",
    "dt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier [Accuracy] = 0.798851\n",
      "DecisionTreeClassifier [Error] = 0.201149 \n"
     ]
    }
   ],
   "source": [
    "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
    "print(\"DecisionTreeClassifier [Accuracy] = %g\"% (dt_accuracy))\n",
    "print(\"DecisionTreeClassifier [Error] = %g \" % (1.0 - dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,18.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|(9,[0,1,4,6],[1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(training_data)\n",
    "rf_prediction = rf_model.transform(test_data)\n",
    "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier [Accuracy] = 0.821839\n",
      "RandomForestClassifier [Error] = 0.178161\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"RandomForestClassifier [Accuracy] = %g\"% (rf_accuracy))\n",
    "print(\"RandomForestClassifier [Error] = %g\" % (1.0 - rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,18.0,1.0,0.0...|\n",
      "|       1.0|       0|[1.0,19.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|(9,[0,1,4,6],[1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\n",
    "gbt_model = gbt.fit(training_data)\n",
    "gbt_prediction = gbt_model.transform(test_data)\n",
    "gbt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-boosted [Accuracy] = 0.793103\n",
      "Gradient-boosted [Error] = 0.206897\n"
     ]
    }
   ],
   "source": [
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Gradient-boosted [Accuracy] = %g\"% (gbt_accuracy))\n",
    "print(\"Gradient-boosted [Error] = %g\"% (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.write().overwrite().save('rf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.RandomForestClassificationModel"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "type(RandomForestClassificationModel.load('rf_model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
      "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
      "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
      "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = data_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|\n",
      "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|\n",
      "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|\n",
      "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|\n",
      "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "|Survived|Pclass| Sex| Age|SibSp|Parch|    Fare|Embarked|Family_Size|Alone|\n",
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "|       0|     1|male|22.0|    0|    0|135.6333|       C|          0|    1|\n",
      "|       0|     1|male|24.0|    0|    1|247.5208|       C|          1|    0|\n",
      "|       0|     1|male|27.0|    0|    2|   211.5|       C|          2|    0|\n",
      "|       0|     1|male|30.0|    0|    0|    31.0|       S|          0|    1|\n",
      "|       0|     1|male|30.0|    0|    0|    35.0|       S|          0|    1|\n",
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_sex = StringIndexer(inputCol=\"Sex\", outputCol=\"Sex_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Sex_index|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+\n",
      "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|      1.0|\n",
      "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|      1.0|\n",
      "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|      1.0|\n",
      "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|      0.0|\n",
      "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|      0.0|\n",
      "|       0|     1|  male|19.0|    3|    2|  263.0|       S|          5|    0|      0.0|\n",
      "|       0|     1|  male|21.0|    0|    1|77.2875|       S|          1|    0|      0.0|\n",
      "|       0|     1|  male|24.0|    0|    0|   79.2|       C|          0|    1|      0.0|\n",
      "|       0|     1|  male|28.0|    0|    0|   47.1|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|28.0|    1|    0|82.1708|       C|          1|    0|      0.0|\n",
      "|       0|     1|  male|29.0|    0|    0|   30.0|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|29.0|    1|    0|   66.6|       S|          1|    0|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0| 25.925|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|   26.0|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|  26.55|       S|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|      0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|  27.75|       C|          0|    1|      0.0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer_sex.fit(train).transform(train).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_embarked = StringIndexer(inputCol=\"Embarked\", outputCol=\"Embarked_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+--------------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Embarked_index|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+--------------+\n",
      "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|           0.0|\n",
      "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|           0.0|\n",
      "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|           1.0|\n",
      "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|           1.0|\n",
      "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|           0.0|\n",
      "|       0|     1|  male|19.0|    3|    2|  263.0|       S|          5|    0|           0.0|\n",
      "|       0|     1|  male|21.0|    0|    1|77.2875|       S|          1|    0|           0.0|\n",
      "|       0|     1|  male|24.0|    0|    0|   79.2|       C|          0|    1|           1.0|\n",
      "|       0|     1|  male|28.0|    0|    0|   47.1|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|28.0|    1|    0|82.1708|       C|          1|    0|           1.0|\n",
      "|       0|     1|  male|29.0|    0|    0|   30.0|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|29.0|    1|    0|   66.6|       S|          1|    0|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0| 25.925|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|   26.0|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|  26.55|       S|          0|    1|           0.0|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|           1.0|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|           1.0|\n",
      "|       0|     1|  male|30.0|    0|    0|  27.75|       C|          0|    1|           1.0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer_embarked.fit(train).transform(train).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(\n",
    "    inputCols=[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"],\n",
    "    outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sex = indexer_sex.fit(train).transform(train)\n",
    "train_embarked = indexer_embarked.fit(train).transform(train_sex)\n",
    "feature = VectorAssembler(\n",
    "    inputCols=[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"],\n",
    "    outputCol=\"features\")\n",
    "result = feature.transform(train_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[1.0,2.0,1.0,2.0,...|\n",
      "|[1.0,25.0,1.0,2.0...|\n",
      "|[1.0,50.0,0.0,0.0...|\n",
      "|[1.0,18.0,1.0,0.0...|\n",
      "|[1.0,19.0,1.0,0.0...|\n",
      "|[1.0,19.0,3.0,2.0...|\n",
      "|[1.0,21.0,0.0,1.0...|\n",
      "|(8,[0,1,4,6],[1.0...|\n",
      "|(8,[0,1,4],[1.0,2...|\n",
      "|[1.0,28.0,1.0,0.0...|\n",
      "|(8,[0,1,4],[1.0,2...|\n",
      "|[1.0,29.0,1.0,0.0...|\n",
      "|(8,[0,1],[1.0,30.0])|\n",
      "|(8,[0,1],[1.0,30.0])|\n",
      "|(8,[0,1,4],[1.0,3...|\n",
      "|(8,[0,1,4],[1.0,3...|\n",
      "|(8,[0,1,4],[1.0,3...|\n",
      "|(8,[0,1,4,6],[1.0...|\n",
      "|(8,[0,1,4,6],[1.0...|\n",
      "|(8,[0,1,4,6],[1.0...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,18.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,1.0,0.0...|\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       0.0|       0|[1.0,29.0,1.0,0.0...|\n",
      "|       0.0|       0|(9,[0,1,4,6],[1.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(training_data)\n",
    "rf_prediction = rf_model.transform(test_data)\n",
    "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.RandomForestClassificationModel"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer_sex, indexer_embarked, feature, rf_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.Pipeline"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|\n",
      "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|\n",
      "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|\n",
      "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|\n",
      "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|\n",
      "|       0|     1|  male|19.0|    3|    2|  263.0|       S|          5|    0|\n",
      "|       0|     1|  male|21.0|    0|    1|77.2875|       S|          1|    0|\n",
      "|       0|     1|  male|24.0|    0|    0|   79.2|       C|          0|    1|\n",
      "|       0|     1|  male|28.0|    0|    0|   47.1|       S|          0|    1|\n",
      "|       0|     1|  male|28.0|    1|    0|82.1708|       C|          1|    0|\n",
      "|       0|     1|  male|29.0|    0|    0|   30.0|       S|          0|    1|\n",
      "|       0|     1|  male|29.0|    1|    0|   66.6|       S|          1|    0|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|    0.0|       S|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0| 25.925|       S|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|   26.0|       S|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|  26.55|       S|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|27.7208|       C|          0|    1|\n",
      "|       0|     1|  male|30.0|    0|    0|  27.75|       C|          0|    1|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.PipelineModel"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model.write().overwrite().save('p_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelineModel.load('p_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "|Survived|Pclass| Sex| Age|SibSp|Parch|    Fare|Embarked|Family_Size|Alone|\n",
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "|       0|     1|male|22.0|    0|    0|135.6333|       C|          0|    1|\n",
      "|       0|     1|male|24.0|    0|    1|247.5208|       C|          1|    0|\n",
      "|       0|     1|male|27.0|    0|    2|   211.5|       C|          2|    0|\n",
      "|       0|     1|male|30.0|    0|    0|    31.0|       S|          0|    1|\n",
      "|       0|     1|male|30.0|    0|    0|    35.0|       S|          0|    1|\n",
      "|       0|     1|male|31.0|    0|    0| 50.4958|       S|          0|    1|\n",
      "|       0|     1|male|36.0|    0|    0|  40.125|       C|          0|    1|\n",
      "|       0|     1|male|36.0|    1|    0|   78.85|       S|          1|    0|\n",
      "|       0|     1|male|38.0|    0|    0|     0.0|       S|          0|    1|\n",
      "|       0|     1|male|45.0|    0|    0|    35.5|       S|          0|    1|\n",
      "|       0|     1|male|45.0|    1|    0|  83.475|       S|          1|    0|\n",
      "|       0|     1|male|45.5|    0|    0|    28.5|       S|          0|    1|\n",
      "|       0|     1|male|46.0|    1|    0|  61.175|       S|          1|    0|\n",
      "|       0|     1|male|47.0|    0|    0| 25.5875|       S|          0|    1|\n",
      "|       0|     1|male|50.0|    1|    0| 106.425|       C|          1|    0|\n",
      "|       0|     1|male|51.0|    0|    1| 61.3792|       C|          1|    0|\n",
      "|       0|     1|male|54.0|    0|    1| 77.2875|       S|          1|    0|\n",
      "|       0|     1|male|56.0|    0|    0|   26.55|       S|          0|    1|\n",
      "|       0|     1|male|64.0|    1|    4|   263.0|       S|          5|    0|\n",
      "|       0|     1|male|71.0|    0|    0| 49.5042|       C|          0|    1|\n",
      "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = p_model.transform(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Sex_index</th>\n",
       "      <th>Embarked_index</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1.0, 22.0, 0.0, 0.0, 135.6333, 0.0, 1.0, 0.0)</td>\n",
       "      <td>[11.665096903435314, 8.334903096564682]</td>\n",
       "      <td>[0.5832548451717658, 0.4167451548282342]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 24.0, 0.0, 1.0, 247.5208, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[10.821004721107837, 9.17899527889216]</td>\n",
       "      <td>[0.5410502360553919, 0.45894976394460807]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 27.0, 0.0, 2.0, 211.5, 2.0, 1.0, 0.0]</td>\n",
       "      <td>[8.783132763059173, 11.216867236940828]</td>\n",
       "      <td>[0.4391566381529587, 0.5608433618470414]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 30.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[14.110720869143059, 5.889279130856943]</td>\n",
       "      <td>[0.7055360434571529, 0.2944639565428472]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 30.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[14.462028058685542, 5.537971941314459]</td>\n",
       "      <td>[0.723101402934277, 0.27689859706572295]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Sex   Age  SibSp  Parch      Fare Embarked  Family_Size  \\\n",
       "0         0       1  male  22.0      0      0  135.6333        C            0   \n",
       "1         0       1  male  24.0      0      1  247.5208        C            1   \n",
       "2         0       1  male  27.0      0      2  211.5000        C            2   \n",
       "3         0       1  male  30.0      0      0   31.0000        S            0   \n",
       "4         0       1  male  30.0      0      0   35.0000        S            0   \n",
       "\n",
       "   Alone  Sex_index  Embarked_index  \\\n",
       "0      1        0.0             1.0   \n",
       "1      0        0.0             1.0   \n",
       "2      0        0.0             1.0   \n",
       "3      1        0.0             0.0   \n",
       "4      1        0.0             0.0   \n",
       "\n",
       "                                         features  \\\n",
       "0  (1.0, 22.0, 0.0, 0.0, 135.6333, 0.0, 1.0, 0.0)   \n",
       "1  [1.0, 24.0, 0.0, 1.0, 247.5208, 1.0, 1.0, 0.0]   \n",
       "2     [1.0, 27.0, 0.0, 2.0, 211.5, 2.0, 1.0, 0.0]   \n",
       "3      (1.0, 30.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0)   \n",
       "4      (1.0, 30.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0)   \n",
       "\n",
       "                             rawPrediction  \\\n",
       "0  [11.665096903435314, 8.334903096564682]   \n",
       "1   [10.821004721107837, 9.17899527889216]   \n",
       "2  [8.783132763059173, 11.216867236940828]   \n",
       "3  [14.110720869143059, 5.889279130856943]   \n",
       "4  [14.462028058685542, 5.537971941314459]   \n",
       "\n",
       "                                 probability  prediction  \n",
       "0   [0.5832548451717658, 0.4167451548282342]         0.0  \n",
       "1  [0.5410502360553919, 0.45894976394460807]         0.0  \n",
       "2   [0.4391566381529587, 0.5608433618470414]         1.0  \n",
       "3   [0.7055360434571529, 0.2944639565428472]         0.0  \n",
       "4   [0.723101402934277, 0.27689859706572295]         0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+-----+--------+-----------+--------------+---------+\n",
      "|Pclass| Age|SibSp|Parch|    Fare|Family_Size|Embarked_index|Sex_index|\n",
      "+------+----+-----+-----+--------+-----------+--------------+---------+\n",
      "|     1|22.0|    0|    0|135.6333|          0|           1.0|      0.0|\n",
      "|     1|24.0|    0|    1|247.5208|          1|           1.0|      0.0|\n",
      "|     1|27.0|    0|    2|   211.5|          2|           1.0|      0.0|\n",
      "|     1|30.0|    0|    0|    31.0|          0|           0.0|      0.0|\n",
      "|     1|30.0|    0|    0|    35.0|          0|           0.0|      0.0|\n",
      "+------+----+-----+-----+--------+-----------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select([\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- Family_Size: integer (nullable = true)\n",
      " |-- Alone: integer (nullable = false)\n",
      " |-- Sex_index: double (nullable = false)\n",
      " |-- Embarked_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline model [Accuracy] = 0.815789\n",
      "Pipeline model [Error] = 0.184211 \n"
     ]
    }
   ],
   "source": [
    "p_accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
    "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "                  .addGrid(rf_classifier.maxDepth, [2,3, 4])\\\n",
    "                  .addGrid(rf_classifier.maxBins, [2, 3, 4])\\\n",
    "                  .addGrid(rf_classifier.minInfoGain, [0.05, 0.1, 0.15])\\\n",
    "                  .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                            estimatorParamMaps=paramGrid,\n",
    "                            evaluator=evaluator,\n",
    "                            trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.tuning.TrainValidationSplitModel"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_5276b993fbf5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaObject id=o15105"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel.stages[-1]._java_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 2\n",
      "Num Trees: 3\n",
      "Impurity: 0.05\n"
     ]
    }
   ],
   "source": [
    "jo = model.bestModel.stages[-1]._java_obj\n",
    "print('Max Depth: {}'.format(jo.getMaxDepth()))\n",
    "print('Num Trees: {}'.format(jo.getMaxBins()))\n",
    "print('Impurity: {}'.format(jo.getMinInfoGain()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
